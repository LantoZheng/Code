#!/usr/bin/env python3
"""
LMStudio è¿æ¥æµ‹è¯•å·¥å…·
ç”¨äºéªŒè¯ LMStudio æœåŠ¡å™¨æ˜¯å¦æ­£å¸¸è¿è¡Œ
"""

import sys
import argparse
from openai import OpenAI


def test_lmstudio_connection(url: str = "http://localhost:1234/v1"):
    """æµ‹è¯• LMStudio è¿æ¥"""
    
    print(f"ğŸ” æµ‹è¯• LMStudio è¿æ¥: {url}")
    print("=" * 60)
    
    try:
        client = OpenAI(
            api_key="lm-studio",
            base_url=url
        )
        
        # 1. æµ‹è¯•æ¨¡å‹åˆ—è¡¨
        print("\n1ï¸âƒ£  è·å–å¯ç”¨æ¨¡å‹...")
        models = client.models.list()
        
        if not models.data:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ¨¡å‹")
            print("   è¯·åœ¨ LMStudio ä¸­åŠ è½½æ¨¡å‹")
            return False
        
        print(f"âœ… æ‰¾åˆ° {len(models.data)} ä¸ªæ¨¡å‹:")
        for model in models.data:
            print(f"   - {model.id}")
        
        # 2. æµ‹è¯•ç®€å•å¯¹è¯
        print("\n2ï¸âƒ£  æµ‹è¯•å¯¹è¯åŠŸèƒ½...")
        model_id = models.data[0].id
        
        response = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": "è¯·å›å¤'æµ‹è¯•æˆåŠŸ'"}
            ],
            max_tokens=20,
            temperature=0.1
        )
        
        reply = response.choices[0].message.content
        print(f"âœ… æ¨¡å‹å“åº”: {reply}")
        
        # 3. æµ‹è¯• logprobsï¼ˆç”¨äºå›°æƒ‘åº¦è®¡ç®—ï¼‰
        print("\n3ï¸âƒ£  æµ‹è¯• logprobs æ”¯æŒ...")
        try:
            response_with_logprobs = client.chat.completions.create(
                model=model_id,
                messages=[
                    {"role": "user", "content": "æµ‹è¯•"}
                ],
                max_tokens=5,
                logprobs=True
            )
            
            if response_with_logprobs.choices[0].logprobs:
                print("âœ… Logprobs æ”¯æŒæ­£å¸¸")
            else:
                print("âš ï¸  Logprobs å¯èƒ½ä¸å—æ”¯æŒ")
                print("   AI æ£€æµ‹åŠŸèƒ½å¯èƒ½å—é™")
        except Exception as e:
            print(f"âš ï¸  Logprobs æµ‹è¯•å¤±è´¥: {e}")
            print("   AI æ£€æµ‹åŠŸèƒ½å¯èƒ½å—é™")
        
        print("\n" + "=" * 60)
        print("âœ… LMStudio è¿æ¥æµ‹è¯•é€šè¿‡ï¼")
        print(f"âœ… å¯ä»¥ä½¿ç”¨ --lmstudio å‚æ•°è¿è¡Œè„šæœ¬")
        print("\nä½¿ç”¨ç¤ºä¾‹:")
        print(f"  python aidetector_lite.py paper.tex --lmstudio")
        if url != "http://localhost:1234/v1":
            print(f"  python aidetector_lite.py paper.tex --lmstudio --lmstudio-url {url}")
        
        return True
        
    except ConnectionError as e:
        print(f"\nâŒ è¿æ¥å¤±è´¥: {e}")
        print("\nè¯·æ£€æŸ¥:")
        print("  1. LMStudio æ˜¯å¦æ­£åœ¨è¿è¡Œ")
        print("  2. æœ¬åœ°æœåŠ¡å™¨æ˜¯å¦å·²å¯åŠ¨")
        print("  3. ç«¯å£å·æ˜¯å¦æ­£ç¡®")
        print(f"  4. URL æ˜¯å¦æ­£ç¡®: {url}")
        return False
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(
        description='æµ‹è¯• LMStudio è¿æ¥',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æµ‹è¯•é»˜è®¤åœ°å€
  python test_lmstudio.py
  
  # æµ‹è¯•è‡ªå®šä¹‰åœ°å€
  python test_lmstudio.py --url http://localhost:5000/v1
        """
    )
    parser.add_argument(
        '--url',
        default='http://localhost:1234/v1',
        help='LMStudio æœåŠ¡å™¨åœ°å€ï¼ˆé»˜è®¤: http://localhost:1234/v1ï¼‰'
    )
    
    args = parser.parse_args()
    
    success = test_lmstudio_connection(args.url)
    
    if not success:
        print("\nğŸ’¡ éœ€è¦å¸®åŠ©ï¼Ÿ")
        print("   æŸ¥çœ‹è¯¦ç»†æŒ‡å—: LMSTUDIO_GUIDE.md")
        print("   æˆ–è®¿é—®: https://lmstudio.ai/docs")
        sys.exit(1)
    
    sys.exit(0)


if __name__ == '__main__':
    main()

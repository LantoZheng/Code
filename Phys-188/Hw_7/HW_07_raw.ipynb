{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW_07.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2PpyACS0HFI"
   },
   "source": [
    "## Homework 7\n",
    "\n",
    "## <em> Linear Regression, Regularization, and Logistic & Softmax Regression</em>\n",
    "<br>\n",
    "This notebook is arranged in cells. Texts are usually written in the markdown cells, and here you can use html tags (make it bold, italic, colored, etc). You can double click on this cell to see the formatting.<br>\n",
    "<br>\n",
    "The ellipsis (...) are provided where you are expected to write your solution but feel free to change the template (not over much) in case this style is not to your taste. <br>\n",
    "<br>\n",
    "<em>Hit \"Shift-Enter\" on a code cell to evaluate it.  Double click a Markdown cell to edit. </em><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kyi_vhCD0HFK"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8pw4W4j0HFM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "#For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1WoUiO_0HFY"
   },
   "source": [
    "#### Problem 1 - Ising Model\n",
    "\n",
    "In earlier HW, we did a simple ML analysis by fitting datasets generated by polynomials in the presence of noise, and this highlighted the fundamental tension common to all ML models between how well we fit the training dataset and predictions on new data.\n",
    "\n",
    "Here, we consider the problem of learning the Hamiltonian for the Ising model (https://en.wikipedia.org/wiki/Ising_model) using the linear regression. This is a lattice model proposed to explain ferromagnetism in materials. In other physics courses, you learned that elementary particles have an intrinsic property called spin, which carries magnetic moments. The magnetism of a bulk material is made up of the magnetic dipole moments of the atomic spins inside the material. The classical Ising model postulates a lattice with a spin $S$ on each site.\n",
    "\n",
    "Now consider the 1D Ising model with nearest-neighbor interactions\n",
    "\n",
    "$$H[\\boldsymbol{S}]=-J\\sum_{j=1}^L S_{j}S_{j+1}$$\n",
    "\n",
    "on a chain of length $L$ with periodic boundary conditions and $S_j=\\pm 1$ Ising spin variables. $J$ is the nearest-neighbor spin interaction\n",
    "\n",
    "With $J=1$, we draw a large number of spin configurations. We can draw them $n$ number of times: we have $n$ number of $\\boldsymbol{S}^i$, which is a vector of length $L$. Hence, $\\boldsymbol{S}$ is a matrix of $n \\times L$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YHv_pXyN0HFY"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 1. You are given 1000 random Ising states with $L=40$. (i.e. this state matrix $\\boldsymbol{S}$ should have the dimension $1000 \\times 40$, and its array elements are either 1 or -1.) Define a function which computes the energies $H$ given $\\boldsymbol{S}$. Calculate the energies of the first 10 states. (Do not shuffle the states!) </i></span> <br>\n",
    "\n",
    "Hint: Each state $\\boldsymbol{S}^i$ has its own energy, so $H[\\boldsymbol{S}]$ is a vector of length $n=1000$.\n",
    "\n",
    "We adopt the periodic boundary conditions, so when $j=L$, $j+1=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1732057737734,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "agfoptEp0HFZ",
    "outputId": "83fefc0a-6a11-4a1e-e65f-99097798caeb",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "S = np.loadtxt(\"./state.txt\")\n",
    "print( np.shape(S) )\n",
    "print( S )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732057737734,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "YLtLJnDi0HFf",
    "outputId": "025fadf0-92f6-4e54-9dd5-0266ff278446",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "L = 40\n",
    "def ising_energies(S,L):\n",
    "...\n",
    "\n",
    "# calculate Ising energies\n",
    "energies=ising_energies(S,L)\n",
    "\n",
    "print( energies[0:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "G80x_zwq0HFk"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Now, suppose you do not have the knowledge of the above Hamiltonian. Instead, you are given a data set of $i=1\\ldots n$ points of the form $\\{(H[\\boldsymbol{S}^i],\\boldsymbol{S}^i)\\}$. Your task is to learn the Hamiltonian using Linear regression techniques.\n",
    "\n",
    "In the absence of any prior knowledge, one sensible choice is the all-to-all Ising model\n",
    "\n",
    "$$\n",
    "H_\\mathrm{model}[\\boldsymbol{S}^i] = - \\sum_{j=1}^L \\sum_{k=1}^L J_{j,k}S_{j}^iS_{k}^i.\n",
    "$$\n",
    "Notice that this model is uniquely defined by the non-local coupling strengths $J_{jk}$ which we want to learn. Importantly, this model is linear in ${\\mathbf J}$ which makes it possible to use linear regression.\n",
    "\n",
    "To apply linear regression, we would like to recast this model in the form\n",
    "$$\n",
    "H_\\mathrm{model}^i \\equiv \\mathbf{X}^i \\cdot \\mathbf{J},\n",
    "$$\n",
    "\n",
    "where the vectors $\\mathbf{X}^i$ represent all two-body interactions $\\{S_{j}^iS_{k}^i \\}_{j,k=1}^L$, and the index $i$ runs over the samples in the data set. To make the analogy complete, we can also represent the dot product by a single index $p = \\{j,k\\}$, i.e. $\\mathbf{X}^i \\cdot \\mathbf{J}=X^i_pJ_p$. Note that the regression model does not include the minus sign, so we expect to learn negative $J$'s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mJhYy9K-0HFl"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 2. Create the matrix $\\mathbf{X}$. Print $\\mathbf{X}$. </i></span> <br>\n",
    "\n",
    "Hint: For each state $i$, we have the state vector $\\boldsymbol{S}^i$. $\\mathbf{X}^i$ = $\\boldsymbol{S}^i_{.T} \\otimes \\boldsymbol{S}^i_{.T}$, where $\\otimes$ is the outer product. (https://en.wikipedia.org/wiki/Outer_product)\n",
    "\n",
    "The dimension of $\\mathbf{X}^i$ is $L \\times L$. Hence, $\\mathbf{X}$ has the diemension $n \\times L \\times L$. Reshape it so that it has the dimension $n \\times L*L$ ($1000 \\times 1600$).\n",
    "\n",
    "You can either use the for-loop or use np.einsum to do the outer product (https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.einsum.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732057738141,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "eH4axP-70HFl",
    "outputId": "b15185af-69b0-4c28-b21a-f41b8623f957",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "X = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1732057738574,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "vkOEJJH33Yil",
    "outputId": "def71a87-4f7b-4413-dbe2-6cafd6943235",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XRUvQjwK0HFq"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "We can now do the linear regression.\n",
    "$$\n",
    "H_\\mathrm{model}^i \\equiv \\mathbf{X}^i \\cdot \\mathbf{J},\n",
    "$$\n",
    "Hence, you have data ($\\mathbf{X}, H$)\n",
    "\n",
    "<span style=\"color:blue\"> <i> 3. Split the data into training and test samples. We choose that the first 70% of $n$ states are training samples, the remaining 30% test samples. No need to shuffle the data because we are already given the random set of states. Print the diemension of training and test samples.</i></span> <br>\n",
    "\n",
    "Hint: Here, H means $H[\\boldsymbol{S}]$ or $H[\\mathbf{X}]$ we calculated in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1732057741127,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "NNqY5dWg0HFr",
    "outputId": "622fb1cf-a112-40e7-8e71-54ecccbbd83f",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "X_train= ...\n",
    "Y_train= ...\n",
    "X_test= ...\n",
    "Y_test= ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "W1Un00BK0HFw"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "In earlier HW, you used \"linear_model.LinearRegression()\" from scikit-learn to do the linear regression and found that using a complex model can result in overfitting. To resolve such issues, we use regularization in machine learning. A regression model that uses $L_1$ regularization technique is called Lasso Regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and model which uses $L_2$ is called Ridge Regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html).\n",
    "\n",
    "First, set up Lasso and Ridge regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gs2NRq8p0HFx"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "lasso = linear_model.Lasso()"
   ]
  },
  {
   "attachments": {
    "3cdabb82-0e85-4042-93e1-07522a6f733b.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "i-xG9ThG0HF1"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "For each regression model, do the following:\n",
    "\n",
    "1. Choose the regularization parameter $\\lambda$.\n",
    "2. Set the parameter using `.set_params()` <br>\n",
    "    e.g. `lambda = 1; ridge.set_params(alpha=lambda)`\n",
    "3. Fit the model<br>\n",
    "    e.g. `ridge.fit(training X samples, training H samples)`\n",
    "4. Compute the coefficient of determination $R^2$ of the prediction. This quantifies the performance of prediction.\n",
    "\n",
    "![image.png](attachment:3cdabb82-0e85-4042-93e1-07522a6f733b.png)\n",
    "\n",
    "    e.g. `ridge.score(training or test X samples, training or test H samples)`\n",
    "\n",
    "<span style=\"color:blue\"> <i> 4. Let lambda = np.logspace(-4, 5, 10). Compute $R^2$ score for each lambda value and plot it as a function of lambda. Do both Ridge and LASSO regression. Also, make sure to show results for both training and test samples. (4 plots, or 4 lines on the same plot) </i></span> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvTKk3nL0HF2",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Use these as lists or arrays for the result:\n",
    "\n",
    "train_errors_ridge = ...\n",
    "test_errors_ridge = ...\n",
    "\n",
    "train_errors_lasso = ...\n",
    "test_errors_lasso = ...\n",
    "\n",
    "# set regularisation strength values\n",
    "lmbdas = ...\n",
    "\n",
    "# Compute the R^2 score:\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 2452,
     "status": "ok",
     "timestamp": 1732057755620,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "mybMIGfF0kCS",
    "outputId": "2308fe59-d87c-4a97-d72d-128ecf546bf1",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fpV2TmMn0HF6"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "You should find that the regularization parameter $\\lambda$ affects the Ridge and LASSO regressions at scales, separated by a few orders of magnitude. Therefore, it is considered good practice to always check the performance for the given model and data with $\\lambda$.\n",
    "\n",
    "At $\\lambda\\to 0$ and $\\lambda\\to\\infty$, both models overfit the data, as can be seen from the deviation of the test errors from unity (dashed lines), while the training curves stay at unity.\n",
    "\n",
    "While the Ridge regression test curves are monotonic, the LASSO test curve is not -- suggesting the optimal LASSO regularization parameter is $\\lambda\\approx 10^{-2}$. At this sweet spot, the Ising interaction weights ${\\bf J}$ contain only nearest-neighbor terms (as did the model the data was generated from).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWqX3Uwq0HF7"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8Ab8iDA0HF7"
   },
   "source": [
    "So far we have focused on learning from datasets for which there is a continuous output. Classification problems, however, are concerned with outcomes taking the form of discrete variables (i.e. categories). Here, given a spin configuration of, say, the 2D Ising model, weâ€™d like to identify its phase (e.g. ordered/disordered).\n",
    "\n",
    "Onsager proved that this model undergoes a thermal phase transition in the thermodynamic limit from an ordered ferromagnet with all spins aligned to a disordered phase at the critical temperature $T_c/J=2/\\log(1+\\sqrt{2})\\approx 2.26$.\n",
    "\n",
    "An interesting question to ask is whether one can train a statistical model to distinguish between the two phases of the Ising model. If successful, this can be used to locate the position of the critical point in more complicated models where an exact analytical solution has so far remained elusive.\n",
    "\n",
    "In other words, given an Ising state, we would like to classify whether it belongs to the ordered or the disordered phase, without any additional information other than the spin configuration itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xcbgq_ct0HF8"
   },
   "source": [
    "To this end, we consider the 2D Ising model on a $40\\times 40$ square lattice, and use Monte-Carlo (MC) sampling to prepare $10^4$ states at every fixed temperature $T$ out of a pre-defined set. Using Onsager's criterion, we can assign a label to each state according to its phase: $0$ if the state is disordered, and $1$ if it is ordered. Our goal is to predict the phase of a sample given the spin configuration.\n",
    "\n",
    "First, load the data for the following three types of phases: ordered ($T/J<2.0$), critical ($2.0\\leq T/J\\leq 2.5)$ and disordered ($T/J>2.5$).\n",
    "\n",
    "We are given data for $T/J=1.0$, $T/J=2.25$, and $T/J=3.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQtsj9Ku0HF9"
   },
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "\n",
    "# state vector\n",
    "file_name = \"./Ising2DFM_reSample_L40_T=All_labels.pkl\"\n",
    "state_vector = pickle.load(open(file_name,'rb'))\n",
    "\n",
    "# ordered phases\n",
    "file_name = \"./Ising2DFM_reSample_L40_T=1.00.pkl\"\n",
    "data = pickle.load(open(file_name,'rb'))\n",
    "data = np.unpackbits(data).reshape(-1, 1600)\n",
    "data=data.astype('int')\n",
    "data[np.where(data==0)]=-1 # map 0 state to -1 (Ising variable can take values +/-1)\n",
    "\n",
    "X_ordered=data\n",
    "Y_ordered=state_vector[30000:40000]\n",
    "\n",
    "# critical phases\n",
    "file_name = \"./Ising2DFM_reSample_L40_T=2.25.pkl\"\n",
    "data = pickle.load(open(file_name,'rb'))\n",
    "data = np.unpackbits(data).reshape(-1, 1600)\n",
    "data=data.astype('int')\n",
    "data[np.where(data==0)]=-1\n",
    "\n",
    "X_critical=data\n",
    "Y_critical=state_vector[80000:90000]\n",
    "\n",
    "# disordered phases\n",
    "file_name = \"./Ising2DFM_reSample_L40_T=3.00.pkl\"\n",
    "data = pickle.load(open(file_name,'rb'))\n",
    "data = np.unpackbits(data).reshape(-1, 1600)\n",
    "data=data.astype('int')\n",
    "data[np.where(data==0)]=-1\n",
    "\n",
    "X_disordered=data\n",
    "Y_disordered=state_vector[110000:120000]\n",
    "\n",
    "L = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPHODUp10HGB"
   },
   "source": [
    "You have $\\textbf{X}$ for ordered, critical and disordered phases and corresponding state vector $Y$.\n",
    "For each phase (ordered, critical or disordered), we have 500 different $40\\times 40$ square lattices. So $\\textbf{X}$ has the dimension $500 \\times 40 \\times 40$. We reshape it into $500 \\times 40*40$ = $500 \\times 1600$. The state vector is a vector of length 500.\n",
    "\n",
    "Run the below cell to plot examples of typical states of the 2D Ising model for three different temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 1079,
     "status": "ok",
     "timestamp": 1732057757033,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "E2y7SFKc0HGC",
    "outputId": "b4307a1e-b38f-41c7-ca59-cf9a3b0db245"
   },
   "outputs": [],
   "source": [
    "# plot few Ising states\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "cmap_args=dict(cmap='plasma_r')\n",
    "\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "axarr[0].imshow(X_ordered[100].reshape(L,L),**cmap_args)\n",
    "axarr[0].set_title('$\\\\mathrm{ordered\\\\ phase}$',fontsize=16)\n",
    "axarr[0].tick_params(labelsize=16)\n",
    "\n",
    "axarr[1].imshow(X_critical[100].reshape(L,L),**cmap_args)\n",
    "axarr[1].set_title('$\\\\mathrm{critical\\\\ region}$',fontsize=16)\n",
    "axarr[1].tick_params(labelsize=16)\n",
    "\n",
    "im=axarr[2].imshow(X_disordered[100].reshape(L,L),**cmap_args)\n",
    "axarr[2].set_title('$\\\\mathrm{disordered\\\\ phase}$',fontsize=16)\n",
    "axarr[2].tick_params(labelsize=16)\n",
    "\n",
    "fig.subplots_adjust(right=2.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cl4qvNBf0HGG"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 5. Combine ordered phase samples and disordered phase samples using np.concatenate. Using train_test_split (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), split it into training and test samples. Set train_size = 0.5. (50% of $X$ is our training samples.) Print the dimension of training and test samples. </i></span> <br>\n",
    "\n",
    "Using logistic regression, we will investigate how accurately we can distinguish between ordered and disordered phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1732057757034,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "4-ydWWKh0HGH",
    "outputId": "782a96fc-c616-4c01-d2ec-a3ad2e80d23f",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "X_train,X_test,Y_train,Y_test= ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GJImCDgN0HGK"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Here, we compare the performance of two different optimization routines: a liblinear (the default one for scikit's logistic regression, https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), and stochastic gradient descent (SGD, https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html). It is important to note that all these methods have built-in regularizers, and doing regularization is crucial in order to prevent overfitting.\n",
    "\n",
    "For each optimization routine, do the following:\n",
    "\n",
    "1. Choose the regularization parameter $\\lambda$.\n",
    "2. Define the logistic regressor <br>\n",
    "    e.g. $\\textbf{liblinear}$: `logreg=linear_model.LogisticRegression(C=1.0/lambda,random_state=1,verbose=0,max_iter=1E3,tol=1E-5)`<br>\n",
    "    e.g. $\\textbf{SGD}$: `logreg_SGD = linear_model.SGDClassifier(loss='log', penalty='l2', alpha=lmbda, max_iter=100, shuffle=True, random_state=1, learning_rate='optimal')`<br>\n",
    "    Use the above parameters, but you can play with them if you wish.\n",
    "3. Fit the model<br>\n",
    "    e.g. `logreg.fit(training X samples, training H samples)`\n",
    "4. Compute the mean accuracy on the given data.\n",
    "    e.g. `logreg.score(training or test X samples, training or test H samples)`\n",
    "\n",
    "<span style=\"color:blue\"> <i> 6. Let `lambda = np.logspace(-5,5,11)`. Compute the mean accuracy for each lambda value and plot it as a function of lambda. Do both liblinear and SGD. Also, show results for both training, test samples, and critical phase samples. (6 plots) What do you find? </i></span> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVW_5bhe0HGL",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YM2DfPVU0HGP"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pWaIZXm0HGP"
   },
   "source": [
    "#### Problem 2 - Back to MNIST\n",
    "\n",
    "Now, we generalize logistic regression to the case of multiple categories which is called Softmax regression. A paradigmatic example of SoftMax regression is the MNIST classification problem. The goal is to find a statistical model which recognizes the ten handwritten digits. There are numerous practical applications of such a task, pretty much anywhere one can imagine dealing with large quantities of numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rR-Vv4jH0HGQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "# Load MNIST data\n",
    "X = np.loadtxt(\"./mnistX.dat\")\n",
    "Y = np.loadtxt(\"./mnistY.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1732058100024,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "g1QObg810-P_",
    "outputId": "75cad9aa-2828-44f9-e82c-ffdf4f92cc31"
   },
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Wxned6jb0HGW"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "\"$X$\" contains information about the given MNIST digits. We have a 28x28 pixel grid, so each image is a vector of length 784; we have 3800 images (digits), so $X$ is a 3800x784 matrix. \"$Y$\" is a label (0-9; the category to which each image belongs) vector of length 3800.\n",
    "\n",
    "<span style=\"color:blue\"> <i> 1. Randomly shuffle data and split them into training and test samples using train_test_split. Let train_size = 0.8. Print the dimension of training and test samples. </i></span> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1732058100024,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "n6zucMyi0HGX",
    "outputId": "4dff1ce6-22ac-4035-858a-5f0a01d5c81a",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "random_state = check_random_state(rng_seed)\n",
    "\n",
    "...\n",
    "\n",
    "# pick training and test data sets\n",
    "X_train, X_test, Y_train, Y_test = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YbzsaP-B0HGd"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 2. Choose any five images and show what the images look like. Print the corresponding labels. </i></span> <br>\n",
    "\n",
    "Hint: each image is a vector of length 784. So reshape it into a 28x28 matrix.<br>\n",
    "$\\ \\ $ `X_0 = X_train[0]`<br>\n",
    "$\\ \\ $  `X_0 = X_0.reshape((28, 28))`<br>\n",
    "Then, make a plot using imshow.<br>\n",
    "$\\ \\ $  `plt.imshow(X_0, cmap=plt.cm.gray)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "executionInfo": {
     "elapsed": 2440,
     "status": "ok",
     "timestamp": 1732058104019,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "Domf505r0HGd",
    "outputId": "a5215aac-500d-491c-dd96-3d76fbfb53f7",
    "scrolled": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ia9ipWpf0HGh"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Now, do logistic regression in the following way:\n",
    "\n",
    "1. Scale data to have zero mean and unit variance (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) <br>\n",
    "  `scaler = StandardScaler()` <br>\n",
    "  `X_train = scaler.fit_transform(X_train)` <br>\n",
    "  `X_test = scaler.transform(X_test)` <br>\n",
    "2. Make an instance of the model using LogisticRegression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Try \"liblinear\" and \"sag\" optimization algorithms.<br>\n",
    "  $\\textbf{liblinear}$: Use solver='liblinear' and use L1 norm in the penalization (penalty='l1'). Also set C=1e5 and tol=.3<br>\n",
    "  $\\textbf{sag}$: Use solver='sag' and use L2 norm in the penalization (penalty='l2'). Also set C=1e5 and tol=.1<br>\n",
    "  e.g. `model = LogisticRegression(...)` <br>\n",
    "3. Train the model on the data <br>\n",
    "  e.g. `model.fit(training X sample, training Y samples)` <br>\n",
    "4. Predict the labels of test data.<br>\n",
    "  e.g. `digit_predict = model.predict(test X samples)` <br>\n",
    "5. Compute the accuracy<br>\n",
    "  e.g. `model.score(test X samples, test Y samples)` <br>\n",
    "  \n",
    "<span style=\"color:blue\"> <i> 3. Using both liblinear and sag solvers, compute the accuracy of the test samples. Also, measure the training time (how long it takes to train the model on the data) using time.time().  </i></span> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2022,
     "status": "ok",
     "timestamp": 1732058106039,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "l063TGr10HGh",
    "outputId": "71947667-db1f-47da-f104-dd122ee2e20e",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "...\n",
    "print('liblinear:')\n",
    "print('Run time: %.3f s' % run_time_liblinear)\n",
    "print('accuracy: %.3f' % score_liblinear)\n",
    "\n",
    "t0 = time.time()\n",
    "...\n",
    "print('sag:')\n",
    "print('Run time: %.3f s' % run_time_SGD)\n",
    "print('accuracy: %.3f' % score_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CIZ4-YLS0HGm"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<span style=\"color:blue\"> <i> 4. Choose any 15 images and show what the images look like. What are the predicted labels corresponding to them? Take a look at the misclassified samples. Use the sag solver. </i></span> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2960,
     "status": "ok",
     "timestamp": 1732058108997,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "c6R71JVB0HGm",
    "outputId": "dce408e8-bffe-46af-d121-9b93bb5b7ee0",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xhiwDXjo0HGq"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Here, we have 10 classes and 784 features. Using \"coef_\", we can get the coefficient of the features in the decision function. These are basically classication \"weights.\"\n",
    "\n",
    "<span style=\"color:blue\"> <i> 5. Obtain the coefficient of the features for the model using the sag solver. (`coef = sag.coef_`) This is a 10x784 matrix. (number of classes x number of features) Reshape it into 28x28 and make a plot for each class. How do they look? Can you recognize the digits? </i></span> <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1732058109457,
     "user": {
      "displayName": "Henry Liu",
      "userId": "02481607702682765299"
     },
     "user_tz": 480
    },
    "id": "MQg7_1Iv0HGq",
    "outputId": "da519a56-b2fd-4766-e3ab-c60221257f27",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "k-SVW19s0HGu"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit the notebook (not the zip) to Gradescope! For the PDF submission, use Cmd + P to get the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "p188_288_hw7",
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> energies_correct = np.array([8.0, 4.0, 0.0, 0.0, 12.0, -4.0, 4.0, 8.0, -4.0, -4.0])\n>>> assert np.all(energies[0:10] == energies_correct), f'Incorrect energies: {energies[0:10]}.'\n>>> print('q1.1 public tests passed.')\nq1.1 public tests passed.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2": {
     "name": "q1.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X.shape == (1000, 1600), f'Incorrect shape for X: {X.shape}.'\n>>> print('q1.2 public tests passed.')\nq1.2 public tests passed.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3": {
     "name": "q1.3",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape == (700, 1600), f'Incorrect shape for X_train: {X_train.shape}.'\n>>> assert X_test.shape == (300, 1600), f'Incorrect shape for X_test: {X_test.shape}.'\n>>> print('q1.3 public test 1 passed.')\nq1.3 public test 1 passed.\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert Y_train.shape == (700,), f'Incorrect shape for Y_train: {Y_train.shape}.'\n>>> assert Y_test.shape == (300,), f'Incorrect shape for Y_test: {Y_test.shape}.'\n>>> print('q1.3 public test 2 passed.')\nq1.3 public test 2 passed.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.4": {
     "name": "q1.4",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert train_errors_ridge.shape == lmbdas.shape, f'Incorrect shape for train_errors_ridge: {train_errors_ridge.shape}.'\n>>> assert train_errors_lasso.shape == lmbdas.shape, f'Incorrect shape for train_errors_lasso: {train_errors_lasso.shape}.'\n>>> print('q1.4 public test 1 passed.')\nq1.4 public test 1 passed.\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert train_errors_ridge[0] > train_errors_ridge[-1], f'Incorrect errors'\n>>> assert test_errors_ridge[0] > test_errors_ridge[-1], f'Incorrect errors'\n>>> assert train_errors_lasso[0] > train_errors_lasso[-1], f'Incorrect errors'\n>>> assert test_errors_lasso[0] > test_errors_lasso[-1], f'Incorrect errors'\n>>> print('q1.4 public test 2 passed.')\nq1.4 public test 2 passed.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.5": {
     "name": "q1.5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape == (10000, 1600), f'Incorrect shape for X_train: {X_train.shape}.'\n>>> assert Y_train.shape == (10000,), f'Incorrect shape for Y_train: {Y_train.shape}.'\n>>> print('q1.5 public test passed.')\nq1.5 public test passed.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape == (3040, 784), f'Incorrect shape for X_train: {X_train.shape}.'\n>>> assert Y_test.shape == (760,), f'Incorrect shape for Y_test: {Y_test.shape}.'\n>>> print('q2.1 public test passed.')\nq2.1 public test passed.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert score_liblinear >= 0.82, f'score_liblinear too low: {score__liblinear}.'\n>>> assert score_SGD >= 0.83, f'score_SGD too low: {score_SGD}.'\n>>> print('q2.3 public test passed.')\nq2.3 public test passed.\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

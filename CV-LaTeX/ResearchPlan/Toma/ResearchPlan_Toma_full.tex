% Clean XeLaTeX document for the Research Plan - FULL VERSION
\documentclass[12pt,a4paper]{article}
% Use fontspec for XeLaTeX
\usepackage{fontspec}
% Use a common system font; change if you prefer another installed font
\setmainfont{Times New Roman}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{setspace}
\onehalfspacing
\usepackage{microtype}
% Use biblatex for bibliography management with biber backend
\usepackage[backend=biber,style=numeric,sorting=none]{biblatex}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{csquotes}
\addbibresource{references.bib}

% Bibliography: use biblatex + biber. Run sequence: xelatex -> biber -> xelatex -> xelatex
% Citations in the document use \cite{key} and will be rendered by biblatex.
\title{Research Plan}
\author{Xiaoyang Zheng}
\date{\today}

\begin{document}
\maketitle
\begin{center}
    \large \textbf{AI-Enabled Multi-Objective Inverse Design of Chiral Metasurfaces for Biosensing via Moth-Eye Template Nanofabrication}
\end{center}
\sloppy

\begin{abstract}
This research plan outlines a project to develop a novel Artificial Intelligence (AI) framework for the inverse design of chiral plasmonic metasurfaces, specifically tailored for the ``Moth-eye film'' template fabrication process recently employed in the Toma laboratory. This work introduces three key innovations to address critical gaps in the current state-of-the-art:
\begin{enumerate}
  \item A generative, on-demand design methodology using a Generative Adversarial Network (GAN), moving beyond slower iterative search algorithms,
  \item A fabrication-aware approach where the AI is ``taught'' the specific geometric constraints of the Toma lab's ``Moth-eye film'' template process, ensuring all generated designs are inherently manufacturable, and
  \item A multi-objective optimization strategy to synergistically co-optimize for both chiroptical response (Circular Dichroism) and colorimetric sensing sensitivity.
\end{enumerate}
By encoding manufacturing rules directly into a parameter-based conditional GAN (cGAN), this project will bridge the persistent ``design-to-fabrication gap''. The project will culminate in hands-on fabrication and experimental validation of the AI-generated designs, demonstrating a complete design-to-device pipeline. The ultimate goal is to deliver a library of high-performance, experimentally viable designs for the next generation of spectrometer-free chiral biosensors, directly empowering the experimental capabilities of the Toma group.
\end{abstract}

\section{Research Background}

\subsection{The Biosensing Challenge: Detecting Molecular Chirality at Point-of-Care}
The detection of biomolecular chirality is a critical challenge in biosensing, with profound implications for drug discovery, disease diagnostics, and fundamental biological research. Most biomolecules---proteins, nucleic acids, sugars---exhibit intrinsic chirality, and their biological function is intimately tied to their three-dimensional handedness. However, these molecules produce extremely weak chiral optical signals (circular dichroism, CD), typically requiring expensive laboratory instrumentation (CD spectrometers) and large sample volumes, making point-of-care and field-deployable sensing impractical~\cite{nanophotonic_biosensors_acs,nanophotonic_biosensors_review}.

Professor Mana Toma's research group addresses this translational bottleneck by developing plasmonic chiral metasurfaces that amplify biomolecular CD signals by orders of magnitude, enabling spectrometer-free, colorimetric detection suitable for mobile health diagnostics~\cite{toma_researches,toma_orcid}. The key innovation lies in engineering plasmonic nanostructures with carefully designed geometric chirality that resonantly couples with target biomolecules, transforming weak CD signals into readily observable color changes visible to the naked eye or smartphone cameras. This paradigm shift---from bulky laboratory equipment to portable, low-cost sensors---has the potential to democratize chiral biosensing for applications ranging from rapid disease screening to environmental monitoring~\cite{nanophotonic_biosensors_acs}.

\subsection{Fabrication Constraint: The Moth-Eye Template as an Enabling Technology}
A critical challenge in translating metasurface designs from simulation to functional biosensors is scalable, cost-effective fabrication. Traditional nanofabrication methods (electron-beam lithography, focused ion beam) are prohibitively expensive and slow for practical biosensor production. The Toma group has pioneered the use of industrially manufactured ``moth-eye films''---originally developed for anti-reflective coatings---as nanoimprint templates for plasmonic metasurface fabrication~\cite{motheye_nil_metasurface,nil_metasurface_review}. This approach leverages existing mass-production infrastructure, dramatically reducing fabrication costs and enabling reproducible, large-area sensor production.

However, this fabrication strategy imposes strict geometric constraints: achievable nanostructure geometries are limited to those compatible with the moth-eye template's periodic conical profile. While this constraint ensures manufacturability, it fundamentally restricts the accessible design space. From a biosensing perspective, this creates a critical optimization challenge: \textit{how can we identify the optimal sensor design within this constrained geometric space to maximize both chiroptical signal enhancement and analyte binding sensitivity?}

\subsection{The AI-Driven Design Opportunity: Bridging the Gap for Biosensor Optimization}
Traditional metasurface design relies on manual parameter sweeps or physics-based optimization, which become intractable when simultaneously optimizing multiple biosensor performance metrics (CD signal strength, spectral sensitivity, binding selectivity) within fabrication-imposed constraints. Recent advances in AI-driven inverse design offer a transformative solution~\cite{dl_nanophotonics_researching,ai_metasurface_vae_gan}, yet current approaches suffer from critical limitations for biosensor applications.

Existing methods often employ iterative search algorithms~\cite{ml_metaplasmonic_biosensors} that must re-optimize from scratch for each new target biomolecule, making rapid sensor customization impossible. Recent deep learning approaches for chiral metasurfaces~\cite{dl_3d_chiral_metasurfaces,dl_customized_chiral,nn_chiral_nanodimer} demonstrate neural network potential but typically produce freeform, pixel-based designs incompatible with the moth-eye template process. Furthermore, most frameworks optimize single metrics (e.g., CD enhancement) while ignoring equally critical biosensing parameters like spectral shift sensitivity upon analyte binding~\cite{inverse_chiroptical_response}.

This research directly addresses these biosensing-critical gaps through three innovations: (1) a generative GAN framework~\cite{conditional_gan_nanophotonics,generative_metasurface_umbc} that rapidly generates on-demand sensor designs for diverse target biomolecules without re-training, (2) fabrication-aware, parameter-based design outputs guaranteeing moth-eye template compatibility, and (3) multi-objective co-optimization balancing chiroptical signal strength and colorimetric sensing sensitivity. By encoding both fabrication constraints and biosensing performance requirements directly into the AI framework, this work aims to deliver a practical design tool that accelerates the development of next-generation chiral biosensors for clinical and field applications.

\section{Problem Statement}
While AI-driven inverse design is promising, current frameworks are ill-suited for the specific needs of an experimental group like Professor Toma's~\cite{dl_nanophotonics_researching,nanophotonic_biosensors_review}. They often produce designs incompatible with scalable fabrication methods like the moth-eye template process~\cite{nil_metasurface_review} and fail to co-optimize for the multiple, competing performance metrics essential for high-performance biosensors~\cite{ml_metaplasmonic_biosensors}. The design of chiral metasurfaces, in particular, is crucial for enhancing the weak signals from biomolecules~\cite{nn_chiral_nanodimer,inverse_chiroptical_response} but presents a complex optimization challenge. This creates a critical need for a specialized AI-driven design framework that can: (1) operate exclusively within the geometric design space defined by the moth-eye template process, guaranteeing manufacturability, (2) simultaneously optimize for both strong chiroptical signal and high sensing sensitivity, and (3) rapidly generate a diverse portfolio of viable design candidates, enabling selection processes that balance peak performance with fabrication tolerance.

\section{Proposed Work and Objectives}
The proposed work is to develop, train, and validate a novel AI-driven inverse design framework based on a conditional Generative Adversarial Network (cGAN) that is specifically tailored to the moth-eye fabrication process~\cite{dl_nanophotonics_rg}. The specific research objectives are:

\begin{enumerate}
  \item To digitize the moth-eye design space by defining a parametric model that mathematically describes the range of achievable nanostructure geometries.
  \item To develop and rigorously validate a cGAN-based predictive design tool where the input ``condition'' is a vector of desired performance targets and the output is a set of manufacturable geometric parameters.
  \item To generate a comprehensive library of optimized, manufacturable chiral metasurface designs.
  \item To experimentally fabricate and validate the AI-generated designs, characterizing their morphology, optical properties, and sensing performance to demonstrate the complete design-to-device pipeline.
\end{enumerate}

To systematically address the multidisciplinary nature of this project, the research is organized into three interconnected technical phases:

\begin{itemize}
  \item \textbf{Phase 1 (Data Generation):} Development of automated FDTD simulation pipeline, systematic sampling of the moth-eye parameter space, and generation of high-quality training datasets comprising parameter-performance pairs.
  \item \textbf{Phase 2 (AI Model Development):} Implementation of surrogate models and cGAN architectures in PyTorch, training with multi-objective loss functions, and validation against simulation benchmarks.
  \item \textbf{Phase 3 (Experimental Validation):} Fabrication of top-ranked designs using the moth-eye template process, morphological characterization via SEM, optical validation through CD spectroscopy, and biosensing performance assessment.
\end{itemize}

\section{Methods}
The methodology is organized into three sequential yet interconnected phases that leverage my background in computational physics, AI, and experimental characterization~\cite{cv_zheng}.

\textbf{Phase 1: Dataset Generation via Automated FDTD Simulation}

\begin{itemize}
  \item \textit{Parameter space definition:} In close consultation with Prof. Toma, I will define a parametric model describing the moth-eye design space, including pillar height ($h$), diameter ($d$), period ($p$), displacement ($\Delta x$), and rotation angle ($\theta$).
  \item \textit{Automated simulation pipeline:} An automated Python script will systematically sample thousands of unique geometric parameter sets and perform FDTD simulations to compute optical responses (transmission/reflection spectra, CD signals) and sensing performance metrics (spectral shifts upon analyte binding).
  \item \textit{Data curation:} The resulting dataset will consist of paired observations: (geometric parameters, optical response, sensing sensitivity), with rigorous quality control to ensure simulation convergence and physical validity.
\end{itemize}

\textbf{Phase 2: Development and Training of Parameter-Based cGAN}

\begin{itemize}
  \item \textit{Surrogate model development:} A forward-predicting neural network will first be trained on the FDTD dataset to rapidly predict performance metrics from geometric parameters. This surrogate model enables fast evaluation during GAN training.
  \item \textit{cGAN architecture:} The Generator network will be designed to output geometric parameter vectors rather than pixelated images, ensuring inherent manufacturability. The network will be conditioned on target performance vectors (desired CD strength, sensing sensitivity) to enable multi-objective design~\cite{benchmark_dl_inverse,conditional_gan_nanophotonics}. Recent advances in GAN-based inverse design for nanophotonics~\cite{rgan_metasurface,gan_nanophotonic_inverse,generative_metasurface_umbc} demonstrate the viability of this approach for high-dimensional design spaces.
  \item \textit{Training protocol:} The cGAN will be trained using a combined loss function incorporating reconstruction accuracy, adversarial loss, and performance prediction from the surrogate model. Extensive data augmentation and domain randomization will enhance generalization.
  \item \textit{Validation:} Model performance will be assessed through FDTD validation of generated designs, quantifying prediction accuracy and design diversity.
\end{itemize}

\textbf{Phase 3: Experimental Fabrication and Validation}

\begin{itemize}
  \item \textit{Design selection:} The trained cGAN will generate a comprehensive library of candidate designs. Top-ranked designs balancing performance and fabrication robustness will be selected for experimental validation.
  \item \textit{Fabrication:} Following the Toma lab protocol, I will fabricate selected designs using the commercial moth-eye film as a nanoimprint template, followed by metal deposition via thermal evaporation.
  \item \textit{Morphological characterization:} SEM imaging will verify geometric fidelity, with quantitative analysis comparing measured parameters against design specifications~\cite{cv_zheng}.
  \item \textit{Optical validation:} CD spectroscopy will measure chiroptical response ($CD = R_{LCP} - R_{RCP}$), with comparison to FDTD predictions~\cite{chiral_metasurface_holography}.
  \item \textit{Biosensing performance:} Proof-of-concept sensing experiments will assess colorimetric/spectral shifts upon analyte binding, validating the multi-objective optimization strategy~\cite{dl_nanophotonics_rg}.
\end{itemize}

\section{Evaluation and Success Criteria}
The success of the proposed research will be evaluated through the following quantitative metrics:

\begin{itemize}
  \item \textit{Dataset quality:} Generation of a high-quality dataset with over 10,000 unique, converged FDTD simulations comprehensively covering the defined moth-eye parameter space.
  \item \textit{AI model performance:} The trained cGAN must generate design parameters that, when validated by FDTD simulation, meet the input target performance vector with less than 10\% deviation in both CD strength and sensing sensitivity metrics.
  \item \textit{Fabrication fidelity:} Successful fabrication of at least one AI-designed metasurface, with geometric features (verified by SEM analysis) matching the design parameters within 15\% tolerance~\cite{cv_zheng}.
  \item \textit{Experimental performance validation:} The fabricated device must exhibit measurable chiroptical response and demonstrate detectable colorimetric/spectral shift upon exposure to a model analyte, with results qualitatively matching trends predicted by simulations.
  \item \textit{System-level impact:} Demonstration of the complete design-to-device pipeline, with quantifiable improvements in design speed (orders of magnitude faster than iterative methods) and generation of a comprehensive design library enabling informed trade-off analysis.
\end{itemize}

\section{Risks and Mitigation}
Several technical risks have been identified, along with corresponding mitigation strategies:

\begin{itemize}
  \item \textit{Simulation accuracy:} FDTD predictions may not perfectly capture fabrication-induced variations or material property uncertainties. \textbf{Mitigation:} Validation simulations will incorporate realistic material models; small-scale fabrication tests will calibrate simulation parameters; and the cGAN training will include noise augmentation to improve robustness to simulation-reality gaps.
  \item \textit{Model generalization:} The cGAN may produce designs that optimize simulation metrics but perform poorly experimentally. \textbf{Mitigation:} Training datasets will include designs spanning the full feasible parameter range; domain randomization techniques will be employed; and early-stage experimental validation of diverse designs will inform model refinement.
  \item \textit{Fabrication challenges:} The moth-eye template process may exhibit batch-to-batch variability or fail for certain geometric parameter combinations. \textbf{Mitigation:} Close collaboration with Prof. Toma's group will establish robust fabrication protocols; the design library will include multiple candidates for each target specification; and fabrication constraints will be explicitly encoded in the parameter bounds used for dataset generation.
  \item \textit{Multi-objective optimization complexity:} Simultaneous optimization of CD strength and sensing sensitivity may reveal fundamental trade-offs limiting achievable performance. \textbf{Mitigation:} The cGAN framework naturally generates Pareto-optimal designs spanning the trade-off frontier; active learning strategies will efficiently explore this space; and the design library will provide transparency regarding achievable performance combinations.
\end{itemize}

\section{Timeline and Milestones}
A representative 24-month timeline with quarterly milestones:

\begin{enumerate}
  \item \textbf{Months 1--6: Foundation and Data Generation}
  \begin{itemize}
    \item Literature review on AI-driven inverse design and chiral metasurfaces
    \item Consultation with Prof. Toma to finalize the moth-eye parameter space
    \item Development of automated FDTD simulation pipeline
    \item Generation of high-quality training dataset ($>$10,000 parameter-performance pairs)
    \item \textit{Milestone 1:} Complete, curated dataset ready for model training
  \end{itemize}

  \item \textbf{Months 7--12: AI Model Development and Training}
  \begin{itemize}
    \item Implementation of surrogate model in PyTorch
    \item Development and training of parameter-based cGAN architecture
    \item Multi-objective loss function optimization
    \item Validation against FDTD simulations on held-out test sets
    \item \textit{Milestone 2:} Trained cGAN achieving $>$90\% prediction accuracy on design objectives
  \end{itemize}

  \item \textbf{Months 13--18: Design Library Generation and Selection}
  \begin{itemize}
    \item Use trained cGAN to generate comprehensive design library
    \item Analysis of design trade-offs and Pareto frontiers
    \item Selection of top candidates balancing performance and fabrication robustness
    \item Detailed fabrication planning and protocol optimization
    \item \textit{Milestone 3:} Comprehensive design library with 3--5 candidates selected for fabrication
  \end{itemize}

  \item \textbf{Months 19--24: Experimental Validation and Thesis Completion}
  \begin{itemize}
    \item Fabrication of selected designs using moth-eye template process
    \item SEM characterization and geometric fidelity assessment
    \item Optical characterization (CD spectroscopy)
    \item Biosensing performance validation with model analytes
    \item Data analysis, thesis writing, and manuscript preparation
    \item \textit{Milestone 4:} Successful Master's thesis defense demonstrating complete design-to-device pipeline and submission of manuscript to high-impact journal
  \end{itemize}
\end{enumerate}

\newpage
\printbibliography[title={References}]

\end{document}
